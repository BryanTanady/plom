# SPDX-License-Identifier: AGPL-3.0-or-later
# Copyright (C) 2025 Bryan Tanady
from plom_server.QuestionClustering.models import (
    QuestionClusteringChore,
    QVClusterLink,
    QVCluster,
)

from plom_server.Papers.models import Paper
from plom_server.Papers.services import PaperInfoService
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import pandas as pd
from abc import abstractmethod
from typing import Any, Sequence, Mapping
from PIL import Image
from sklearn.cluster import AgglomerativeClustering
import cv2
from .image_processing_service import ImageProcessingService
import numpy as np
from io import BytesIO


class ClusteringModel:
    """Interface for clustering model"""

    @abstractmethod
    def cluster_papers(
        self, paper_to_image: Mapping[int, Sequence[np.ndarray]]
    ) -> dict[int, int]:
        """Cluster the given papers

        Args:
            paper_to_image: a dictionary mapping paper number to the
                cropped region used for clustering.

        Returns:
            A dictionary mapping the paper number to their cluster id
        """
        pass


class AttentionPooling(nn.Module):
    def __init__(self, in_features):
        super().__init__()
        self.attention = nn.Sequential(
            nn.Linear(in_features, 512), nn.Tanh(), nn.Linear(512, 1), nn.Softmax(dim=1)
        )

    def forward(self, x):
        # Input: [batch, channels, height, width]
        batch, channels, h, w = x.size()
        # Flatten spatial dimensions: [batch, channels, h*w]
        flattened = x.view(batch, channels, h * w)
        # Permute: [batch, h*w, channels]
        flattened = flattened.permute(0, 2, 1)
        # Compute attention weights: [batch, h*w, 1]
        attn_weights = self.attention(flattened)
        # Weighted sum: [batch, channels]
        return torch.sum(attn_weights * flattened, dim=1)


class MCQClusteringModel(ClusteringModel):
    def __init__(self):
        self.out_features = 11
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # Reconstruct the model architecture and load weights
        model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
        model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)
        in_feats = model.fc.in_features
        model.avgpool = AttentionPooling(in_feats)
        model.fc = nn.Linear(in_feats, self.out_features)
        model = model.to(device)

        model.load_state_dict(
            torch.load("model_cache/mcq_model.pth", map_location=device)
        )
        model.eval()

        self.infer_tf = transforms.Compose(
            [
                transforms.Grayscale(num_output_channels=1),
                transforms.Resize((64, 64)),
                transforms.ToTensor(),
                transforms.Normalize((0.5,), (0.5,)),
            ]
        )

        self.model = model

    def _get_embeddings(self, image: np.ndarray, thresh: float = 0.5):
        """Generate the embeddings (probabilities) for the given image.

        Note: Each feature generated by this model represents a probability.
            Confidence refers to the highest probability for the predictions.

        Args:
            image: the image whose embeddings will be generated
        """
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        x = (
            self.infer_tf(Image.fromarray(image)).unsqueeze(0).to(device)
        )  # shape: [1,3,H,W]

        with torch.no_grad():
            logits = self.model(x)
            probs = torch.softmax(logits, dim=1).cpu().numpy()[0]

        return list(probs)

    def get_embeddings(self, img: np.ndarray) -> list:
        """Get the feature vector for the given image that will be used for clustering.

        Args:
            img: the image whose feature vector will be generated and used for clustering.

        Returns:
            a list representing feature used for clustering. In this model, each feature
            represents a probability for a character.
        """
        # build a structuring element that will bridge any gap ≤ gap_tolerance
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))

        # close small gaps so that what were once multiple components
        # become one big blob in a single connectedComponents call
        closed = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)

        # merges all “nearby” pieces
        n_labels, _, stats, _ = cv2.connectedComponentsWithStats(closed, connectivity=8)

        # get the probs with highest confidence
        for lab in range(1, n_labels):  # skip background
            x, y, w, h, area = stats[lab]
            if area < 100:
                continue

            crop = img[y : y + h, x : x + w]
            bestConfidence, bestFeatures = 0.0, [0] * self.out_features

            probs = self._get_embeddings(crop)
            confidence = max(probs)
            if confidence > bestConfidence:
                bestConfidence = confidence
                bestFeatures = probs

        return bestFeatures

    def cluster_papers(
        self, paper_to_image: dict[int, Sequence[np.ndarray]]
    ) -> dict[int, int]:
        """Cluster papers based on written MCQ responses

        Args:
            paper_to_image: a dictionary mapping paper number to the
                cropped region used for clustering.

        Returns:
            A dictionary mapping the paper number to their cluster id
        """
        data = []
        for pn, image in paper_to_image.items():

            with BytesIO(image) as fh:
                img_pil = Image.open(fh)
                img_arr = np.array(img_pil)

            probs = self.get_embeddings(img_arr)

            datum: dict[Any, Any] = {i: p for i, p in enumerate(probs)}
            datum["paper_num"] = pn
            data.append(datum)

        df = pd.DataFrame(data)

        # Extract the probabilites that will be clustered on
        feature_cols = [i for i in range(11)]
        df[feature_cols] = df[feature_cols].fillna(0)
        X = df[feature_cols].values

        # Cluster based on the probabilities
        clustering_model = AgglomerativeClustering(
            n_clusters=None, distance_threshold=1.0, linkage="ward"
        )
        df["clusterId"] = clustering_model.fit_predict(X)

        # Store into db
        for pn, clusterId in zip(df["paper_num"], df["clusterId"]):
            paper = Paper.objects.get(paper_number=pn)
            qv_cluster, _ = QVCluster.objects.get_or_create(
                question_idx=question_idx,
                version=version,
                clusterId=clusterId,
                page_num=page_num,
                top=top,
                left=left,
                bottom=bottom,
                right=right,
            )
            QVClusterLink.objects.create(paper=paper, qv_cluster=qv_cluster)
